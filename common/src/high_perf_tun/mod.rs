//! High-Performance TUN Handler
//!
//! Cross-platform TUN I/O with platform-specific optimizations:
//! - Linux: io_uring for batched I/O operations
//! - macOS/iOS/Android: writev for vectored I/O
//! - Windows: Overlapped I/O with completion ports
//!
//! Performance gains:
//! - 10-20x syscall reduction via batching
//! - Zero-copy buffer pooling
//! - Adaptive batch sizing based on throughput
//! - Timeout-based auto-flush for low latency

use bytes::BytesMut;
use std::collections::VecDeque;
use std::time::{Duration, Instant};

#[cfg(unix)]
mod unix;
#[cfg(windows)]
mod windows;

#[cfg(unix)]
pub use unix::*;
#[cfg(windows)]
pub use windows::*;

/// Configuration for adaptive batching
#[derive(Debug, Clone)]
pub struct BatchConfig {
    /// Initial batch size
    pub initial_batch_size: usize,
    /// Minimum batch size
    pub min_batch_size: usize,
    /// Maximum batch size
    pub max_batch_size: usize,
    /// Flush timeout (microseconds)
    pub flush_timeout_us: u64,
    /// Target throughput for adaptive sizing (bytes/sec)
    pub target_throughput: u64,
    /// Enable adaptive batch sizing
    pub adaptive: bool,
}

impl Default for BatchConfig {
    fn default() -> Self {
        BatchConfig {
            initial_batch_size: 64,
            min_batch_size: 8,
            max_batch_size: 256,
            flush_timeout_us: 100,            // 100 microseconds
            target_throughput: 1_000_000_000, // 1 GB/s
            adaptive: true,
        }
    }
}

impl BatchConfig {
    /// Config optimized for gaming (low latency)
    pub fn gaming() -> Self {
        BatchConfig {
            initial_batch_size: 16,
            min_batch_size: 4,
            max_batch_size: 32,
            flush_timeout_us: 50,           // 50 microseconds - very aggressive
            target_throughput: 100_000_000, // 100 MB/s
            adaptive: true,
        }
    }

    /// Config optimized for throughput
    pub fn high_throughput() -> Self {
        BatchConfig {
            initial_batch_size: 128,
            min_batch_size: 32,
            max_batch_size: 512,
            flush_timeout_us: 500,             // 500 microseconds
            target_throughput: 10_000_000_000, // 10 GB/s
            adaptive: true,
        }
    }
}

/// High-performance TUN packet batch with adaptive sizing
#[derive(Debug)]
pub struct TunBatch {
    /// Packets ready to send
    pub packets: VecDeque<BytesMut>,
    /// Current batch size limit
    current_batch_size: usize,
    /// Configuration
    config: BatchConfig,
    /// Last flush time for timeout-based flushing
    last_flush: Instant,
    /// Bytes accumulated since last adaptation
    bytes_since_adapt: u64,
    /// Time of last adaptation
    last_adapt: Instant,
}

impl TunBatch {
    pub fn new(max_batch: usize) -> Self {
        Self::with_config(BatchConfig {
            initial_batch_size: max_batch,
            max_batch_size: max_batch,
            ..Default::default()
        })
    }

    pub fn with_config(config: BatchConfig) -> Self {
        let now = Instant::now();
        TunBatch {
            packets: VecDeque::with_capacity(config.max_batch_size),
            current_batch_size: config.initial_batch_size,
            config,
            last_flush: now,
            bytes_since_adapt: 0,
            last_adapt: now,
        }
    }

    /// Add a packet to the batch
    pub fn push(&mut self, packet: BytesMut) {
        self.bytes_since_adapt += packet.len() as u64;
        self.packets.push_back(packet);
    }

    /// Check if batch should be flushed (size or timeout)
    pub fn should_flush(&self) -> bool {
        // Flush if we hit the batch size threshold
        if self.packets.len() >= self.current_batch_size / 2 {
            return true;
        }
        // Flush if timeout exceeded and we have data
        if !self.packets.is_empty() {
            let elapsed = self.last_flush.elapsed();
            if elapsed >= Duration::from_micros(self.config.flush_timeout_us) {
                return true;
            }
        }
        false
    }

    /// Check if batch is full
    pub fn is_full(&self) -> bool {
        self.packets.len() >= self.current_batch_size
    }

    /// Drain all packets and update timing
    pub fn drain(&mut self) -> impl Iterator<Item = BytesMut> + '_ {
        self.last_flush = Instant::now();
        self.packets.drain(..)
    }

    /// Adapt batch size based on throughput (call periodically)
    pub fn adapt(&mut self) {
        if !self.config.adaptive {
            return;
        }

        let elapsed = self.last_adapt.elapsed();
        if elapsed < Duration::from_millis(100) {
            return; // Don't adapt too frequently
        }

        let throughput = self.bytes_since_adapt as f64 / elapsed.as_secs_f64();
        let target = self.config.target_throughput as f64;

        // If throughput is high, increase batch size for efficiency
        // If throughput is low, decrease batch size for lower latency
        let ratio = throughput / target;

        if ratio > 1.2 {
            // High throughput - increase batch size
            self.current_batch_size =
                (self.current_batch_size * 3 / 2).min(self.config.max_batch_size);
        } else if ratio < 0.5 {
            // Low throughput - decrease batch size for lower latency
            self.current_batch_size =
                (self.current_batch_size * 2 / 3).max(self.config.min_batch_size);
        }

        self.bytes_since_adapt = 0;
        self.last_adapt = Instant::now();
    }

    /// Get current batch size
    pub fn current_size(&self) -> usize {
        self.current_batch_size
    }

    /// Number of queued packets
    pub fn len(&self) -> usize {
        self.packets.len()
    }

    pub fn is_empty(&self) -> bool {
        self.packets.is_empty()
    }

    /// Time since last flush
    pub fn time_since_flush(&self) -> Duration {
        self.last_flush.elapsed()
    }
}

impl Default for TunBatch {
    fn default() -> Self {
        Self::with_config(BatchConfig::default())
    }
}

/// TUN I/O statistics with latency tracking
#[derive(Debug, Clone)]
pub struct TunStats {
    pub packets_read: u64,
    pub packets_written: u64,
    pub bytes_read: u64,
    pub bytes_written: u64,
    pub batches_written: u64,
    pub batches_read: u64,
    pub syscalls_saved: u64,
    /// Total write latency in nanoseconds
    pub total_write_latency_ns: u64,
    /// Number of latency samples
    pub latency_samples: u64,
    /// Start time for throughput calculation
    start_time: Instant,
}

impl Default for TunStats {
    fn default() -> Self {
        TunStats {
            packets_read: 0,
            packets_written: 0,
            bytes_read: 0,
            bytes_written: 0,
            batches_written: 0,
            batches_read: 0,
            syscalls_saved: 0,
            total_write_latency_ns: 0,
            latency_samples: 0,
            start_time: Instant::now(),
        }
    }
}

impl TunStats {
    /// Record a write operation with latency
    pub fn record_write(&mut self, packets: u64, bytes: u64, latency_ns: u64) {
        self.packets_written += packets;
        self.bytes_written += bytes;
        self.total_write_latency_ns += latency_ns;
        self.latency_samples += 1;
    }

    /// Record a read operation
    pub fn record_read(&mut self, packets: u64, bytes: u64) {
        self.packets_read += packets;
        self.bytes_read += bytes;
    }

    /// Get average write latency in microseconds
    pub fn avg_write_latency_us(&self) -> f64 {
        if self.latency_samples == 0 {
            0.0
        } else {
            (self.total_write_latency_ns as f64 / self.latency_samples as f64) / 1000.0
        }
    }

    /// Get write throughput in bytes per second
    pub fn write_throughput(&self) -> f64 {
        let elapsed = self.start_time.elapsed().as_secs_f64();
        if elapsed == 0.0 {
            0.0
        } else {
            self.bytes_written as f64 / elapsed
        }
    }

    /// Get read throughput in bytes per second
    pub fn read_throughput(&self) -> f64 {
        let elapsed = self.start_time.elapsed().as_secs_f64();
        if elapsed == 0.0 {
            0.0
        } else {
            self.bytes_read as f64 / elapsed
        }
    }

    /// Get syscall reduction ratio
    pub fn syscall_reduction(&self) -> f64 {
        if self.batches_written == 0 {
            1.0
        } else {
            self.packets_written as f64 / self.batches_written as f64
        }
    }

    /// Format stats as human-readable string
    pub fn summary(&self) -> String {
        format!(
            "TUN Stats: {} pkts written, {} pkts read, {:.1} MB/s write, {:.1} MB/s read, \
             {:.1}x syscall reduction, {:.1}Âµs avg latency",
            self.packets_written,
            self.packets_read,
            self.write_throughput() / 1_000_000.0,
            self.read_throughput() / 1_000_000.0,
            self.syscall_reduction(),
            self.avg_write_latency_us()
        )
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_tun_batch() {
        let mut batch = TunBatch::new(4);
        assert!(batch.is_empty());

        batch.push(BytesMut::from(&b"test"[..]));
        assert_eq!(batch.len(), 1);
        assert!(!batch.is_full());

        batch.push(BytesMut::from(&b"test2"[..]));
        assert!(batch.should_flush()); // 2 >= 4/2
    }
}
