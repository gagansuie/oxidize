name: ML Model Training

on:
  # Run weekly on Sunday at 00:00 UTC
  schedule:
    - cron: '0 0 * * 0'
  # Manual trigger
  workflow_dispatch:
    inputs:
      force_retrain:
        description: 'Force retrain even with few samples'
        required: false
        default: 'false'
        type: boolean

env:
  CARGO_TERM_COLOR: always
  HF_REPO: gagansuie/oxidize-models

jobs:
  train-and-push:
    name: Train Models & Push to HF Hub
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable
        with:
          components: rustfmt, clippy

      - name: Cache cargo registry
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
          key: ${{ runner.os }}-cargo-ml-${{ hashFiles('**/Cargo.lock') }}

      - name: Build ML training binary
        run: cargo build --release -p oxidize-common --features ai

      - name: Setup Python (for HF CLI)
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Hugging Face CLI
        run: pip install "huggingface_hub[cli]"

      - name: Login to Hugging Face
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: hf auth login --token $HF_TOKEN

      - name: Download training data from HF Hub
        run: |
          mkdir -p training_data
          # Download any uploaded training samples
          hf download $HF_REPO --include "training_data/*.json" --local-dir ./hf_download || true
          if [ -d "./hf_download/training_data" ]; then
            cp -r ./hf_download/training_data/* ./training_data/ || true
          fi
          echo "Training samples found: $(find training_data -name '*.json' | wc -l)"

      - name: Train models
        run: |
          # Create model output directory
          mkdir -p /tmp/oxidize_models
          
          # Run training (this would be a dedicated binary in production)
          # For now, we just ensure the build works and models can be created
          echo "Training with $(find training_data -name '*.json' | wc -l) sample files"
          
          # TODO: Replace with actual training binary
          # cargo run --release --bin oxidize-train -- \
          #   --input ./training_data \
          #   --output /tmp/oxidize_models \
          #   --epochs 100

      - name: Push models to HF Hub
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          # Push to HF Hub (uses existing config.json from repo)
          ./hf_repo/hf_push.sh --models || ./hf_repo/hf_push.sh

      - name: Summary
        run: |
          echo "## ML Training Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Training samples**: $(find training_data -name '*.json' | wc -l) files" >> $GITHUB_STEP_SUMMARY
          echo "- **Models pushed to**: https://huggingface.co/$HF_REPO" >> $GITHUB_STEP_SUMMARY
          echo "- **Timestamp**: $(date -u)" >> $GITHUB_STEP_SUMMARY
