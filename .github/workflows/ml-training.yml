name: ML Model Training

on:
  # Daily schedule (3 AM UTC)
  schedule:
    - cron: '0 3 * * *'
  # Manual trigger
  workflow_dispatch:
    inputs:
      force_retrain:
        description: 'Force retrain even with few samples'
        required: false
        default: 'false'
        type: boolean

env:
  CARGO_TERM_COLOR: always
  HF_REPO: gagansuie/oxidize-models

jobs:
  train-and-push:
    name: Train Models & Push to HF Hub
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable
        with:
          components: rustfmt, clippy

      - name: Cache cargo registry
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
          key: ${{ runner.os }}-cargo-ml-${{ hashFiles('**/Cargo.lock') }}

      - name: Build ML training binary
        run: cargo build --release -p oxidize-common --bin oxidize-train --features ai

      - name: Setup Python (for HF CLI)
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Hugging Face CLI
        run: pip install "huggingface_hub[cli]"

      - name: Login to Hugging Face
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: huggingface-cli login --token $HF_TOKEN

      - name: Download training data from HF Hub
        run: |
          mkdir -p training_data
          # Download any uploaded training samples
          huggingface-cli download $HF_REPO --include "training_data/*.json" --local-dir ./hf_download || true
          if [ -d "./hf_download/training_data" ]; then
            cp -r ./hf_download/training_data/* ./training_data/ || true
          fi
          echo "Training samples found: $(find training_data -name '*.json' | wc -l)"

      - name: Train models
        run: |
          # Create model output directory
          mkdir -p ./trained_models
          
          # Run training with synthetic data if no real data exists
          echo "Training with $(find training_data -name '*.json' | wc -l) sample files"
          
          ./target/release/oxidize-train \
            --input ./training_data \
            --output ./trained_models \
            --lstm-epochs 100 \
            --dqn-steps 1000 \
            --generate-synthetic \
            --synthetic-samples 10000 \
            --export-onnx=false \
            --verbose

      - name: Copy models to HF repo
        run: |
          # Copy trained models to hf_repo for upload
          cp ./trained_models/*.safetensors ./hf_repo/ || true
          cp ./trained_models/config.json ./hf_repo/config.json || true
          
          # Create training_data directory in hf_repo
          mkdir -p ./hf_repo/training_data

      - name: Push models to HF Hub
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          cd hf_repo
          huggingface-cli upload $HF_REPO . --repo-type model

      - name: Summary
        run: |
          echo "## ML Training Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Training samples**: $(find training_data -name '*.json' | wc -l) files" >> $GITHUB_STEP_SUMMARY
          echo "- **Models pushed to**: https://huggingface.co/$HF_REPO" >> $GITHUB_STEP_SUMMARY
          echo "- **Timestamp**: $(date -u)" >> $GITHUB_STEP_SUMMARY
